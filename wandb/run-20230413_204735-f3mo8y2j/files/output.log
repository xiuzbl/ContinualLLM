






Loading checkpoint shards: 100%|██████████| 33/33 [00:13<00:00,  2.36it/s]
The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization.
The tokenizer class you load from this checkpoint is 'LLaMATokenizer'.
The class this function is called from is 'LlamaTokenizer'.
04/13/2023 20:48:37 - WARNING - datasets.builder -   Found cached dataset json (/root/.cache/huggingface/datasets/json/default-0cb8404fb3cb3961/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e)
100%|██████████| 1/1 [00:00<00:00, 642.12it/s]
Traceback (most recent call last):
  File "/mnt/data/yingxiu/LLMCODE/run.py", line 140, in <module>
    fire.Fire(main(args))
  File "/mnt/data/yingxiu/LLMCODE/run.py", line 70, in main
    train_val["train"].shuffle().map(generate_and_tokenize_prompt))
  File "/mnt/data/yingxiu/xiuenvs/alpaca3.9/lib/python3.9/site-packages/datasets/arrow_dataset.py", line 563, in wrapper
    out: Union["Dataset", "DatasetDict"] = func(self, *args, **kwargs)
  File "/mnt/data/yingxiu/xiuenvs/alpaca3.9/lib/python3.9/site-packages/datasets/arrow_dataset.py", line 528, in wrapper
    out: Union["Dataset", "DatasetDict"] = func(self, *args, **kwargs)
  File "/mnt/data/yingxiu/xiuenvs/alpaca3.9/lib/python3.9/site-packages/datasets/arrow_dataset.py", line 3004, in map
    for rank, done, content in Dataset._map_single(**dataset_kwargs):
  File "/mnt/data/yingxiu/xiuenvs/alpaca3.9/lib/python3.9/site-packages/datasets/arrow_dataset.py", line 3358, in _map_single
    example = apply_function_on_filtered_inputs(example, i, offset=offset)
  File "/mnt/data/yingxiu/xiuenvs/alpaca3.9/lib/python3.9/site-packages/datasets/arrow_dataset.py", line 3261, in apply_function_on_filtered_inputs
    processed_inputs = function(*fn_args, *additional_args, **fn_kwargs)
TypeError: generate_and_tokenize_prompt() missing 1 required positional argument: 'prompter'